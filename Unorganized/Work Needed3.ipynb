{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Structure Data (https://chrisalbon.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert pandas categorical data for Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "raw_data = {'patient': [1, 1, 1, 2, 2],\n",
    "        'obs': [1, 2, 3, 1, 2],\n",
    "        'treatment': [0, 1, 0, 1, 0],\n",
    "        'score': ['strong', 'weak', 'normal', 'weak', 'strong']}\n",
    "df = pd.DataFrame(raw_data, columns = ['patient', 'obs', 'treatment', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 2, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a label (category) encoder object\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the pandas column\n",
    "le.fit(df['score'])\n",
    "\n",
    "# View the labels (if you want)\n",
    "list(le.classes_)\n",
    "\n",
    "# Apply the fitted encoder to the pandas column\n",
    "le.transform(df['score']) \n",
    "\n",
    "# Convert some integers into their category names\n",
    "list(le.inverse_transform([2, 2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imupting missing class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Create feature matrix with categorical feature\n",
    "X = np.array([[0, 2.10, 1.45], \n",
    "              [1, 1.18, 1.33], \n",
    "              [0, 1.22, 1.27],\n",
    "              [0, -0.21, -1.19],\n",
    "              [np.nan, 0.87, 1.31],\n",
    "              [np.nan, -0.67, -0.22]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 0.  , -0.21, -1.19],\n",
       "       [ 0.  ,  0.87,  1.31],\n",
       "       [ 0.  , -0.67, -0.22]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Imputer object\n",
    "imputer = Imputer(strategy='most_frequent', axis=0)\n",
    "\n",
    "# Fill missing values with most frequent class\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Delete observations with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1, 11.1],\n",
       "       [ 2.2, 22.2],\n",
       "       [ 3.3, 33.3],\n",
       "       [ 4.4, 44.4]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature matrix\n",
    "X = np.array([[1.1, 11.1], \n",
    "              [2.2, 22.2], \n",
    "              [3.3, 33.3], \n",
    "              [4.4, 44.4], \n",
    "              [np.nan, 55]])\n",
    "\n",
    "X[~np.isnan(X).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0        1.1       11.1\n",
       "1        2.2       22.2\n",
       "2        3.3       33.3\n",
       "3        4.4       44.4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data as a data frame\n",
    "df = pd.DataFrame(X, columns=['feature_1', 'feature_2'])\n",
    "\n",
    "# Remove observations with missing values\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect outliers\n",
    "EllipticEnvelope assumes the data is normally distributed and based on that assumption “draws” an ellipse around the data, classifying any observation inside the ellipse as an inlier (labeled as 1) and any observation outside the ellipse as an outlier (labeled as -1). \n",
    "\n",
    "A major limitation of this approach is the need to specify a contamination parameter which is the proportion of observations that are outliers, a value that we don’t know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Create simulated data\n",
    "X, _ = make_blobs(n_samples = 10,\n",
    "                  n_features = 2,\n",
    "                  centers = 1,\n",
    "                  random_state = 1)\n",
    "\n",
    "# Replace the first observation's values with extreme values\n",
    "X[0,0] = 10000\n",
    "X[0,1] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create detector\n",
    "outlier_detector = EllipticEnvelope(contamination=.1)\n",
    "\n",
    "# Fit detector\n",
    "outlier_detector.fit(X)\n",
    "\n",
    "# Predict outliers\n",
    "outlier_detector.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np\n",
    "\n",
    "# Create feature matrix\n",
    "X = np.array([[0.5, 0.5], \n",
    "              [1.1, 3.4], \n",
    "              [1.5, 20.2], \n",
    "              [1.63, 34.4], \n",
    "              [10.9, 3.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create normalizer\n",
    "normalizer = Normalizer(norm='l2')\n",
    "\n",
    "# Transform feature matrix\n",
    "normalizer.transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
